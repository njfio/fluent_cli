[

  {
    "name": "GeminiPro",
    "engine": "gemini",
    "protocol": "https",
    "hostname": "ai.google.dev",
    "port": 443,
    "request_path": "api/python/google/generativeai/GenerativeModel",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_GOOGLE_AI_STUDIO_KEY_01",
    "overrideConfig": {
      "project_id": "497773813500",
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "gemini-1.5-pro-latest",
      "max_tokens": -1,
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 1
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
    "name": "GeminiFlash",
    "engine": "gemini",
    "protocol": "https",
    "hostname": "ai.google.dev",
    "port": 443,
    "request_path": "api/python/google/generativeai/GenerativeModel",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_GOOGLE_AI_STUDIO_KEY_01",
    "overrideConfig": {
      "project_id": "497773813500",
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "gemini-1.5-flash",
      "max_tokens": -1,
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 1
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },

  {
    "name": "Opus",
    "engine": "anthropic",
    "protocol": "https",
    "hostname": "api.anthropic.com",
    "port": 443,
    "request_path": "/v1/messages",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_ANTHROPIC_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "claude-3-opus-20240229",
      "max_tokens": 4000,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "stop_sequences": ["finish\n\n"],
      "stream": false,
      "tools": [
        {
          "name": "get_stock_price",
          "description": "Get the current stock price for a given ticker symbol.",
          "input_schema": {
            "type": "object",
            "properties": {
              "ticker": {
                "type": "string",
                "description": "The stock ticker symbol, e.g. AAPL for Apple Inc."
              }
            },
            "required": ["ticker"]
          }
        }
      ]
    },
    "tweaks": {},
    "timeout_ms": 50000
  },
  {
    "name": "Sonnet",
    "engine": "anthropic",
    "protocol": "https",
    "hostname": "api.anthropic.com",
    "port": 443,
    "request_path": "/v1/messages",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_ANTHROPIC_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "claude-3-sonnet-20240229",
      "max_tokens": 4000,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "stop_sequences": ["finish\n\n"],
      "stream": false,
      "tools": [
        {
          "name": "get_stock_price",
          "description": "Get the current stock price for a given ticker symbol.",
          "input_schema": {
            "type": "object",
            "properties": {
              "ticker": {
                "type": "string",
                "description": "The stock ticker symbol, e.g. AAPL for Apple Inc."
              }
            },
            "required": ["ticker"]
          }
        }
      ]
    },
    "tweaks": {},
    "timeout_ms": 50000
  },  {
    "name": "Sonnet3.5",
    "engine": "anthropic",
    "protocol": "https",
    "hostname": "api.anthropic.com",
    "port": 443,
    "request_path": "/v1/messages",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_ANTHROPIC_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "claude-3-5-sonnet-20240620",
      "max_tokens": 4000,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "stop_sequences": ["finish\n\n"],
      "stream": false,
      "tools": [
        {
          "name": "get_stock_price",
          "description": "Get the current stock price for a given ticker symbol.",
          "input_schema": {
            "type": "object",
            "properties": {
              "ticker": {
                "type": "string",
                "description": "The stock ticker symbol, e.g. AAPL for Apple Inc."
              }
            },
            "required": ["ticker"]
          }
        }
      ]
    },
    "tweaks": {},
    "timeout_ms": 50000
  },
  {
    "name": "Haiku",
    "engine": "anthropic",
    "protocol": "https",
    "hostname": "api.anthropic.com",
    "port": 443,
    "request_path": "/v1/messages",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_ANTHROPIC_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "claude-3-haiku-20240307",
      "max_tokens": 4000,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "stop_sequences": ["finish\n\n"],
      "stream": false,
      "tools": [
        {
          "name": "get_stock_price",
          "description": "Get the current stock price for a given ticker symbol.",
          "input_schema": {
            "type": "object",
            "properties": {
              "ticker": {
                "type": "string",
                "description": "The stock ticker symbol, e.g. AAPL for Apple Inc."
              }
            },
            "required": ["ticker"]
          }
        }
      ]
    },
    "tweaks": {},
    "timeout_ms": 50000
  },

  {
    "name": "Dalle",
    "engine": "dalle",
    "protocol": "https",
    "hostname": "api.openai.com",
    "port": 443,
    "request_path": "/v1/images/generations",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_OPENAI_API_KEY_01",
    "overrideConfig": {
      "model": "dall-e-3",
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "n": 1,
      "user": "example-user-id",
      "size": "1024x1024",
      "style": "vivid",
      "quality": "hd"
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
    "name": "DalleWide",
    "engine": "dalle",
    "protocol": "https",
    "hostname": "api.openai.com",
    "port": 443,
    "request_path": "/v1/images/generations",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_OPENAI_API_KEY_01",
    "overrideConfig": {
      "model": "dall-e-3",
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "n": 1,
      "logprobs": null,
      "echo": false,
      "user": "example-user-id",
      "size": "1792x1024",
      "style": "vivid",
      "quality": "hd"
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
    "name": "DalleVertical",
    "engine": "dalle",
    "protocol": "https",
    "hostname": "api.openai.com",
    "port": 443,
    "request_path": "/v1/images/generations",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_OPENAI_API_KEY_01",
    "overrideConfig": {
      "model": "dall-e-3",
      "max_tokens": 4000,
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "n": 1,
      "logprobs": null,
      "echo": false,
      "user": "example-user-id",
      "size": "1024x1792",
      "style": "vivid",
      "quality": "hd"
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },

  {
    "name": "Omni",
    "engine": "openai",
    "protocol": "https",
    "hostname": "api.openai.com",
    "port": 443,
    "request_path": "v1/chat/completions",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_OPENAI_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "gpt-4o",
      "max_tokens": 4000,
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 1,
      "frequency_penalty": 0,
      "presence_penalty": 0,
      "stop": ["\n\nFinished", "User:"],
      "n": 1,
      "logprobs": null,
      "echo": false,
      "user": "example-user-id"
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
    "name": "OmniAssistant",
    "engine": "open_ai_assistant",
    "protocol": "https",
    "hostname": "api.openai.com",
    "port": 443,
    "request_path": "/v1/chat/completions",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_OPENAI_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 25,
      "stripNewLines": true,
      "modelName": "gpt-4o",
      "max_tokens": -1,
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "assistant_id": "asst_HwtZFIUrYQxenwWU91Z5UBUG",
      "instructions": "Please address the user as Jane Doe. The user has a premium account.",
      "additional_instructions": "Be concise in your responses.",
      "tools": [
        {
          "type": "code_interpreter"
        }
      ],
      "tool_choices": {
        "type": "function", "function": {
          "name": "get_stock_price"
        }
      },
      "metadata": {
        "user_id": "AMBER_FLUENT_SESSION_ID_01",
        "session_id": "AMBER_FLUENT_SESSION_ID_01"
      },
      "stream": false,
      "top_p": 1.0,
      "max_prompt_tokens": -1,
      "max_completion_tokens": -1,
      "truncation_strategy": {
        "type": "auto",
        "last_messages": null
      },
      "tool_choice": "auto",
      "parallel_tool_calls": true,
      "response_format": "auto"
    },

    "tweaks": {},
    "timeout_ms": 5000000
  },

  {
    "name": "Groq-Llama3-70b",
    "engine": "openai",
    "protocol": "https",
    "hostname": "api.groq.com",
    "port": 443,
    "request_path": "/openai/v1/chat/completions",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_GROQ_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "llama3-70b-8192",
      "max_tokens": 4000,
      "openAIApiKey": "AMBER_FLUENT_GROQ_API_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 1,
      "frequency_penalty": 0,
      "presence_penalty": 0,
      "stop": ["\n\nFinished", "User:"],
      "n": 1,
      "logprobs": null,
      "echo": false,
      "user": "example-user-id"
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
    "name": "Groq-Llama3-8b",
    "engine": "openai",
    "protocol": "https",
    "hostname": "api.groq.com",
    "port": 443,
    "request_path": "/openai/v1/chat/completions",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_GROQ_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "llama3-8b-8192",
      "max_tokens": 4000,
      "openAIApiKey": "AMBER_FLUENT_GROQ_API_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 1,
      "frequency_penalty": 0,
      "presence_penalty": 0,
      "stop": ["\n\nFinished", "User:"],
      "n": 1,
      "logprobs": null,
      "echo": false,
      "user": "example-user-id"
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
    "name": "Groq-Mixstral",
    "engine": "openai",
    "protocol": "https",
    "hostname": "api.groq.com",
    "port": 443,
    "request_path": "/openai/v1/chat/completions",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_GROQ_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": " mixtral-8x7b-32768",
      "max_tokens": 4000,
      "openAIApiKey": "AMBER_FLUENT_GROQ_API_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 1,
      "frequency_penalty": 0,
      "presence_penalty": 0,
      "stop": ["\n\nFinished", "User:"],
      "n": 1,
      "logprobs": null,
      "echo": false,
      "user": "example-user-id"
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
    "name": "Groq-Gemma",
    "engine": "openai",
    "protocol": "https",
    "hostname": "api.groq.com",
    "port": 443,
    "request_path": "/openai/v1/chat/completions",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_GROQ_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "stripNewLines": true,
      "modelName": "gemma-7b-it",
      "max_tokens": 4000,
      "openAIApiKey": "AMBER_FLUENT_GROQ_API_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 1,
      "frequency_penalty": 0,
      "presence_penalty": 0,
      "stop": ["\n\nFinished", "User:"],
      "n": 1,
      "logprobs": null,
      "echo": false,
      "user": "example-user-id"
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },

  {
    "name": "SonarLarge",
    "engine": "openai",
    "protocol": "https",
    "hostname": "api.perplexity.ai",
    "port": 443,
    "request_path": "chat/completions",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_PERPLEXITY_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "modelName": "llama-3-sonar-large-32k-online",
      "max_tokens": 0,
      "stream": false,
      "return_citations": true,
      "openAIApiKey": "AMBER_FLUENT_PERPLEXITY_API_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 0.8,
      "frequency_penalty": 0,
      "presence_penalty": 1
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
    "name": "SonarSmall",
    "engine": "openai",
    "protocol": "https",
    "hostname": "api.perplexity.ai",
    "port": 443,
    "request_path": "chat/completions",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_PERPLEXITY_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "modelName": "llama-3-sonar-small-32k-online",
      "max_tokens": 0,
      "stream": false,
      "return_citations": true,
      "openAIApiKey": "AMBER_FLUENT_PERPLEXITY_API_KEY_01",
      "temperature": 0.7,
      "systemMessage": "You are a helpful assistant.",
      "top_p": 0.8,
      "frequency_penalty": 0,
      "presence_penalty": 1
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },

  {
    "name": "CommandR",
    "engine": "cohere",
    "protocol": "https",
    "hostname": "api.cohere.com",
    "port": 443,
    "request_path": "v1/chat",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "chat_id": "",
    "bearer_token": "AMBER_FLUENT_COHERE_API_KEY_01",
    "overrideConfig": {
      "max_iterations": 10,
      "modelName": "command-r",
      "prompt": "You are a helpful assistant.",
      "max_tokens": -1,
      "stream": false,
      "chatHistory": [],
      "temperature": 0.7,
      "connectors": [{"id":"web-search"}]
    },
    "tweaks": {},
    "timeout_ms": 5000000
  },
  {
  "name": "CommandRNightly",
  "engine": "cohere",
  "protocol": "https",
  "hostname": "api.cohere.com",
  "port": 443,
  "request_path": "v1/chat",
  "sessionId": "AMBER_FLUENT_SESSION_ID_01",
  "chat_id": "",
  "bearer_token": "AMBER_FLUENT_COHERE_API_KEY_01",
  "overrideConfig": {
    "max_iterations": 10,
    "modelName": "command-nightly",
    "prompt": "You are a helpful assistant.",
    "max_tokens": -1,
    "stream": false,
    "chatHistory": [],
    "temperature": 0.7,
    "connectors": [{"id":"web-search"}]
  },
  "tweaks": {},
  "timeout_ms": 5000000
},



  {
    "name": "LocalGoogleGeminiChain",
    "engine": "flowise",
    "protocol": "http",
    "hostname": "127.0.0.1",
    "port": 3000,
    "chat_id": "fbaa82fb-6312-4bbd-a841-bdcf2a8c2bba",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "modelName": "gemini-1.5-pro-latest"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
  "name": "LocalGoogleFlashChain",
  "engine": "flowise",
  "protocol": "http",
  "hostname": "127.0.0.1",
  "port": 3000,
  "chat_id": "fbaa82fb-6312-4bbd-a841-bdcf2a8c2bba",
  "request_path": "/api/v1/prediction/",
  "sessionId": "AMBER_FLUENT_SESSION_ID_01",
  "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
  "overrideConfig": {
    "modelName": "gemini-1.5-flash-latest"
  },
  "tweaks": {

  },
  "timeout_ms": 50000
},

  {
    "name": "LocalGPT4SupervisorWorkerFlow",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "127.0.0.1",
    "port": 3000,
    "chat_id": "57ead6df-627f-45c9-948a-9bc2b19e6a2e",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "modelName": {
        "chatOpenAICustom_0": "gpt-4o"
      },
      "openAIApiKey": {
        "chatOpenAICustom_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "temperature": 0,
      "systemMessage": "you are a helpful assistant",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "LocalGPT4SupervisorWorkerBrowserAndGithubFlow",
    "engine": "flowise",
    "protocol": "http",
    "hostname": "127.0.0.1",
    "port": 3000,
    "chat_id": "d6c83c82-3423-4ee9-bb12-152cbdcb8a7c",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {

      "modelName": {
        "chatOpenAICustom_0": "gpt-4o"
      },
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",

      "temperature": 0
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "GPT4SupervisorWorkerBrowserAndGitHubFlowRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "flowise.fluentcli.com",
    "port": 443,
    "chat_id": "d170e885-f0d6-42f1-b27f-8fe6c579ac64",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "modelName": {
        "chatOpenAICustom_0": "gpt-4o"
      },
      "openAIApiKey": {
        "chatOpenAICustom_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "temperature": 0,
      "systemMessage": "you are a helpful assistant",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },

  {
    "name": "StarCoder2HuggingFaceRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "9b252777-f26f-4841-9dc2-fb9db02990e1",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "huggingFaceApiKey": "AMBER_FLUENT_HUGGINGFACE_API_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "FlowiseConversationalRetrivalQAChainRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "225a8391-4e6b-4815-af6e-51993c2c2185",
    "request_path": "/api/v1/prediction/",
    "upsert_path": "/api/v1/vector/upsert/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "chainName": "FlowiseConversationalRetrivalQAChainRepoCloud",
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "searchApiKey": "AMBER_FLUENT_SEARCHAPI_KEY_ID_01",
      "accessToken": "AMBER_FLUENT_GITHUB_PAT_KEY_01",
      "pineconeApiKey": "AMBER_FLUENT_PINECONE_API_KEY_01",
      "repoLink": "https://github.com/FlowiseAI/Flowise/",
      "branch":  "main",
      "chunkOverlap": 500,
      "chunkSize": 3000,
      "recursive": true,
      "maxRetries" : 3,
      "language":{
        "codeTextSplitter_0": "js"
      },
      "modelName": {
        "chatOpenAI_0": "gpt-4-turbo-preview",
        "openAIEmbeddings_0": "text-embedding-3-large"
      },
      "pineconeIndex": "large",
      "returnSourceDocuments": true
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "FluentCLIConversationalRetrivalQAChainRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "225a8391-4e6b-4815-af6e-51993c2c2185",
    "request_path": "/api/v1/prediction/",
    "upsert_path": "/api/v1/vector/upsert/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "chainName": "FluentCLIConversationalRetrivalQAChainRepoCloud",
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "searchApiKey": "AMBER_FLUENT_SEARCHAPI_KEY_ID_01",
      "accessToken": "AMBER_FLUENT_GITHUB_PAT_KEY_01",
      "pineconeApiKey": "AMBER_FLUENT_PINECONE_API_KEY_01",

      "repoLink": "https://github.com/njfio/fluent_cli/",
      "branch":  "main",
      "chunkOverlap": 500,
      "chunkSize": 3000,
      "recursive": true,
      "maxRetries" : 3,
      "language":{
        "codeTextSplitter_0": "rust"
      },
      "pineconeIndex": "fluentcli",
      "modelName": {
        "chatOpenAI_0": "gpt-4-turbo-preview",
        "openAIEmbeddings_0": "text-embedding-3-large"
      },
      "returnSourceDocuments": true
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "FluentCLIAstraRetrivalQAChainRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "e976497f-7fa6-40b0-a879-ed1b49ffd4bc",
    "request_path": "/api/v1/prediction/",
    "upsert_path": "/api/v1/vector/upsert/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "returnSourceDocuments": true,
      "chainName": "FluentCLIAstraRetrivalQAChainRepoCloud",
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "searchApiKey": "AMBER_FLUENT_SEARCHAPI_KEY_ID_01",
      "accessToken": "AMBER_FLUENT_GITHUB_PAT_KEY_01",

      "repoLink": "https://github.com/njfio/fluent_cli/",
      "branch":  "main",
      "recursive": true,
      "maxRetries" : 3,
      "language":{
      },
      "modelName": {
        "chatOpenAI_0": "gpt-4o",
        "openAIEmbeddings_0": "text-embedding-ada-002"
      },

      "applicationToken": "AMBER_ASTRA_LANGFLOW_APP_TOKEN",
      "dbEndPoint": "https://ee12d7de-4703-467d-aaee-8cde05f10f47-us-east-2.apps.astra.datastax.com",
      "astraNamespace": "fluent",
      "astraCollection": "fluent_collection",
      "vectorDimension": 1536,
      "similarityMetric": "cosine",
      "topK": 10,
      "searchType": "similarity",
      "fetchK": 20,
      "lambda": 0.5,
      "temperature": 0.1,
      "maxTokens": 1500,
      "topP": 0.9,
      "frequencyPenalty": 0.5,
      "presencePenalty": 0.6,
      "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
      "responsePrompt": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
      "allowImageUploads": true,
      "imageResolution": "high",
      "webPath": "https://njf.gitbook.io/fluent_cli_gitbook",
      "shouldLoadAllPaths": true,
      "maxConcurrency": 5,
      "stripNewLines": false,
      "batchSize": 100,
      "chunkSize": 1000,
      "chunkOverlap": 200
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },

  {
    "name": "LangFlowExample",
    "engine": "langflow",
    "protocol": "https",
    "hostname": "njfio-langflow-preview.hf.space",
    "port": 443,
    "request_path": "/api/v1/run/",
    "chat_id": "b711ccd8-fc6f-4faf-acf1-bf155dd29c92?",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "input_value_key": "input_value",
    "sessionId": "",
    "output_type": "chat",
    "input_type": "chat",
    "overrideConfig": {

    },
    "tweaks": {
      "Prompt-PbKIE": {
        "template": "you are a helpful assistant",
        "user_input": "give me some markdown syntax examples"
      },
      "OpenAIModel-Wnn5j": {
        "openai_api_key": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "model_name": "gpt-4-turbo-preview"
      },
      "ChatOutput-6PVYx": {
        "session_id": "AMBER_FLUENT_SESSION_ID_01"
      },
      "ChatInput-6JYUL": {
        "input_value": "",
        "session_id": "AMBER_FLUENT_SESSION_ID_01"
      }
    },
    "timeout_ms": 50000
  },
  {
    "name": "LangFlowChainOfThoughtExample",
    "engine": "langflow",
    "protocol": "https",
    "hostname": "njfio-langflow-preview.hf.space",
    "port": 443,
    "request_path": "/api/v1/run/",
    "chat_id": "c787b6ca-66aa-4994-b932-07d755b44b6e",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "input_value_key": "TextInput-2NhZ7",
    "sessionId": "",
    "output_type": "chat",
    "input_type": "chat",
    "overrideConfig": {

    },
    "tweaks": {
      "Prompt-I7E8t": {
        "template": "Given the question below, come up with a rationale to answer it.\n\nQuestion: {question}\nRationale: ",
        "question": ""
      },
      "ChatOutput-p8C7z": {
        "record_template": "{text}",
        "return_record": false,
        "sender": "Machine",
        "sender_name": "Reasoning"
      },
      "OpenAIModel-LQZp6": {
        "max_tokens": 256,
        "model_kwargs": "{}",
        "model_name": "gpt-3.5-turbo",
        "openai_api_key": "AMBER_OPENAI_API_KEY_01",
        "stream": false,
        "temperature": 0.1
      },
      "TextInput-2NhZ7": {
        "input_value": "I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?",
        "record_template": ""
      },
      "Prompt-Qzo1h": {
        "template": "Given the question and rationale below, come up with the final answer.\n\nQuestion: {question}\nRationale: {rationale}\nFinal Answer: ",
        "question": "",
        "rationale": ""
      },
      "OpenAIModel-TjiUS": {
        "max_tokens": 256,
        "model_kwargs": "{}",
        "model_name": "gpt-3.5-turbo",
        "openai_api_key": "AMBER_OPENAI_API_KEY_01",
        "stream": false,
        "temperature": 0.1
      },
      "ChatOutput-WGgql": {
        "record_template": "{text}",
        "return_record": false,
        "sender": "Machine",
        "sender_name": "Answer"
      }
    },
    "timeout_ms": 50000
  },
  {
    "name": "LangFlowParallelWorkersExample",
    "engine": "langflow",
    "protocol": "https",
    "hostname": "njfio-langflow-preview.hf.space",
    "port": 443,
    "request_path": "/api/v1/run/",
    "chat_id": "6a459fdb-cfbe-4788-ae01-871ad19c8c9c",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "input_value_key": "TextInput-J8Raj",
    "input_value": "message",
    "sessionId": "123",
    "output_type": "chat",
    "input_type": "chat",
    "overrideConfig": {
    },
    "tweaks": {
      "CustomComponent-BrJAP": {
        "API_MODEL_KEY": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "detail_text": true,
        "internal_prompt_instruction": "",
        "internal_prompt_theme": "",
        "model": "gpt-4o",
        "web": ""
      },
      "ChatOutput-ZfVZ4": {
        "record_template": "{text}",
        "return_record": true,
        "sender": "Machine",
        "sender_name": ""
      },
      "TextInput-l7she": {
        "input_value": "You should create 5 topics for this theme",
        "record_template": ""
      },
      "TextInput-auD4z": {
        "input_value": "I want you to generate topics related to",
        "record_template": ""
      },
      "TextInput-J8Raj": {
        "input_value": "Artificial intelligence (AI) is a branch of computer science that involves creating systems capable of performing tasks that would typically require human intelligence. These tasks include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction. Prominent AI applications include expert systems, natural language processing (NLP), speech recognition, and machine vision.  AI is categorized into two main types:  Narrow AI: Also known as weak AI, this type of artificial intelligence operates within a limited context and is a simulation of human intelligence. Narrow AI is often focused on performing a single task extremely well and while these machines may seem intelligent, they are operating under far more constraints and limitations than even the most basic human intelligence. General AI: Also known as strong AI, this type of AI systems possess the ability to perform any intellectual task that a human being can. General AI is still a largely theoretical concept in current research, though numerous breakthroughs in AI capabilities bring the possibility of future development closer. Authors and thought leaders in AI and related fields often discuss its implications, including ethical considerations, the impact on jobs, privacy, and the future interaction between humans and intelligent machines. Their works provide a crucial insight into how AI continues to evolve and reshape our world.",
        "record_template": ""
      },
      "TextInput-l9fag": {
        "input_value": "AI Applied to Agriculture",
        "record_template": ""
      }
    },
      "timeout_ms": 50000
  },
  {
    "name": "LangFlowGeneratedKnowledgeExample",
    "engine": "langflow",
    "protocol": "https",
    "hostname": "njfio-langflow-preview.hf.space",
    "port": 443,
    "request_path": "/api/v1/run/",
    "chat_id": "3c750603-e925-4345-836b-4a08dca3b057",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "input_value_key": "input_value",
    "sessionId": "",
    "output_type": "chat",
    "input_type": "chat",
    "overrideConfig": {

    },
    "tweaks": {
      "Prompt-eJcEQ": {
        "template": "Input: Greece is larger than mexico.\nKnowledge: Greece is approximately 131,957 sq km, while Mexico is approximately 1,964,375 sq km, making Mexico 1,389% larger than Greece.\nInput: Glasses always fog up.\nKnowledge: Condensation occurs on eyeglass lenses when water vapor from your sweat, breath, and ambient humidity lands on a cold surface, cools, and then changes into tiny drops of liquid, forming a film that you see as fog. Your lenses will be relatively cool compared to your breath, especially when the outside air is cold.\nInput: A fish is capable of thinking.\nKnowledge: Fish are more intelligent than they appear. In many areas, such as memory, their cognitive powers match or exceed those of ’higher’ vertebrates including non-human primates. Fish’s long-term memories help them keep track of complex social relationships.\nInput: A common effect of smoking lots of cigarettes in one’s lifetime is a higher than normal chance of getting lung cancer.\nKnowledge: Those who consistently averaged less than one cigarette per day over their lifetime had nine times the risk of dying from lung cancer than never smokers. Among people who smoked between one and 10 cigarettes per day, the risk of dying from lung cancer was nearly 12 times higher than that of never smokers.\nInput: A rock is the same size as a pebble.\nKnowledge: A pebble is a clast of rock with a particle size of 4 to 64 millimetres based on the Udden-Wentworth scale of sedimentology. Pebbles are generally considered larger than granules (2 to 4 millimetres diameter) and smaller than cobbles (64 to 256 millimetres diameter).\nInput: {input}\nKnowledge:",
        "input": ""
      },
      "OpenAIModel-c4otl": {
        "max_tokens": 256,
        "model_kwargs": "{}",
        "model_name": "gpt-4o",
        "openai_api_key": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "stream": false,
        "temperature": 0.1
      },
      "ChatOutput-4xE50": {
        "record_template": "{text}",
        "return_record": false,
        "sender": "Machine",
        "sender_name": "Knowledge"
      },
      "TextInput-EBfvh": {
        "input_value": "Part of golf is trying to get a higher point total than others.",
        "record_template": ""
      },
      "Prompt-OtULG": {
        "template": "{knowledge}\n\nGiven the knowledge context above, answer:\n\n{statement}\n\nIs the statement TRUE or FALSE?",
        "knowledge": "",
        "statement": ""
      },
      "OpenAIModel-VlSn0": {
        "max_tokens": 256,
        "model_kwargs": "{}",
        "model_name": "gpt-4o",
        "openai_api_key": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "stream": false,
        "temperature": 0.1
      },
      "ChatOutput-ibNlY": {
        "record_template": "{text}",
        "return_record": false,
        "sender": "Machine",
        "sender_name": "Answer"
      }
    },
    "timeout_ms": 50000
  },
  {
    "name": "LangFlowBlogWriterExample",
    "engine": "langflow",
    "protocol": "https",
    "hostname": "njfio-langflow-preview.hf.space",
    "port": 443,
    "request_path": "/api/v1/run/",
    "chat_id": "1034ce6b-6aae-4c98-8db6-242cdc129a6e",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "input_value_key": "TextInput-i7mxW",
    "sessionId": "",
    "output_type": "chat",
    "input_type": "chat",
    "overrideConfig": {
    },
    "tweaks": {
      "Prompt-mfY6j": {
        "template": "Reference 1:\n\n{reference_1}\n\n---\n\nReference 2:\n\n{reference_2}\n\n---\n\nReference 3:\n\n{reference_3}\n\n---\n\nReference 4:\n\n{reference_4}\n\n---\n\n{instructions}\n\nBlog: \n\n\n",
        "reference_1": "",
        "reference_2": "",
        "instructions": "",
        "reference_3": "",
        "reference_4": ""
      },
      "URL-dVtT6": {
        "urls": [
          "https://www.promptingguide.ai/techniques/prompt_chaining"
        ]
      },
      "ChatOutput-ohw3s": {
        "record_template": "{text}",
        "return_record": false,
        "sender": "Machine",
        "sender_name": "AI"
      },
      "OpenAIModel-QAE75": {
        "max_tokens": 1024,
        "model_kwargs": "{}",
        "model_name": "gpt-4o",
        "openai_api_key": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "stream": true,
        "temperature": 0.1
      },
      "URL-Fzv2k": {
        "urls": [
          "https://www.promptingguide.ai/introduction/basics"
        ]
      },
      "TextInput-i7mxW": {
        "input_value": "Use the references above for style to write a new blog/tutorial about prompt engineering techniques. Suggest non-covered topics.",
        "record_template": ""
      },
      "URL-kY40m": {
        "urls": [
          "https://www.promptingguide.ai/introduction/basics"
        ]
      },
      "URL-Fas2L": {
        "urls": [
          "https://www.promptingguide.ai/introduction/basics"
        ]
      }
    },
    "timeout_ms": 50000


  },
  {
    "name": "LangFlowChainOfThoughtExample",
    "engine": "langflow",
    "protocol": "https",
    "hostname": "njfio-langflow-preview.hf.space",
    "port": 443,
    "request_path": "/api/v1/run/",
    "chat_id": "2f224ad7-3579-4e4b-8964-18678fd2ee01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "input_value_key": "input_value",
    "input_value": "message",
    "sessionId": "",
    "output_type": "chat",
    "input_type": "chat",
    "overrideConfig": {

    },
    "tweaks": {
      "Prompt-DoqBg": {
      },
      "ChatOutput-g2gga": {},
      "OpenAIModel-WvjnV": {
        "model_kwargs": {},
        "openai_api_key": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "TextInput-0pH93": {
        "input_value": "message"
      },
      "Prompt-xiPZp": {
      },
      "OpenAIModel-dCDLX": {
        "openai_api_key": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "ChatOutput-mBx2g": {}
    },
    "timeout_ms": 50000
  },

  {
    "name": "CohereChainRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "36b556a8-1ce4-4735-ad21-dcc3cda95a2f",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "modelName": {
        "chatAnthropic_0": "claude-3-sonnet-20240229",
        "chatOpenAI_0": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "systemMessagePrompt": "you are a helpful assistant",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },

  {
    "name": "GPT4oToolAgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "e7f3499e-7c1d-4638-a92f-f2951d0515d0",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "modelName": {
        "chatOpenAICustom_0": "gpt-4o"
      },
      "openAIApiKey": {
        "chatOpenAICustom_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "temperature": 0,
      "systemMessage": "you are a helpful assistant",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "GPTChainRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "974e8273-3494-4c88-8dac-06c4c2ed6454",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "modelName": {
        "chatAnthropic_0": "claude-3-sonnet-20240229",
        "chatOpenAI_0": "gpt-4o",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "systemMessagePrompt": "you are a helpful assistant",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "GPT4ImageUploadRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "f2c53912-c4a7-46c1-a384-5b0e8e3bf615",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "chainName": "GPT4ImageUploadRepoCloud",
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "allowImageUploads": true,
      "temperature": 0.7
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "GPT4ToolAgentWithTextFileUpsertRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "85e4e8b3-28c9-4405-b4d9-9ec270cbabfe",
    "request_path": "/api/v1/prediction/",
    "upsert_path": "/api/v1/vector/upsert/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "chainName": "GPT4ToolAgentWithTextFileUpsertRepoCloud",
      "chunkOverlap": 500,
      "chunkSize": 3000,
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "modelName": {
        "chatOpenAI_0": "gpt-4-turbo-preview",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "name": "local_retriever",
      "description": "local retriever"
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "GPT4ToolAgentWithCSVFileUpsert",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "48b416ed-a5df-4cc2-accd-fa7fc5126992",
    "request_path": "/api/v1/prediction/",
    "upsert_path": "/api/v1/vector/upsert/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "chainName": "GPT4ToolAgentWithTextFileUpsertRepoCloud",
      "pineconeApiKey": "AMBER_FLUENT_PINECONE_API_KEY_01",
      "chunkOverlap": 200,
      "chunkSize": 1000,
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "modelName": {
        "chatOpenAI_0": "gpt-4-turbo-preview",
        "openAIEmbeddings_0": "text-embedding-ada-002"
      },
      "name": "local_retriever",
      "description": "local retriever",
      "pineconeIndex": "textfiles"
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "GPT4ToolAgentWithUpsertRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "931b1268-561d-494d-8f37-b5f5caac4466",
    "request_path": "/api/v1/prediction/",
    "upsert_path": "/api/v1/vector/upsert/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "accessToken": "AMBER_FLUENT_GITHUB_PAT_KEY_01",
      "repoLink": "https://github.com/njfio/fluent_cli/",
      "branch":  "main",
      "chunkOverlap": 200,
      "chunkSize": 1000,
      "chainName": "GPT4ToolAgentWithUpsertRepoCloud",
      "openAIApiKey": {
        "openAIEmbeddings_1": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "searchApiKey": "AMBER_FLUENT_SEARCHAPI_KEY_ID_01",
      "pineconeApiKey": "AMBER_FLUENT_PINECONE_API_KEY_01",
      "recursive": true,
      "maxRetries" : 3,
      "language":{
        "codeTextSplitter_0": "rust"
      },
      "pineconeIndex": "fluentcli",
      "modelName": {
        "chatOpenAI_0": "gpt-4-turbo-preview",
        "openAIEmbeddings_1": "text-embedding-ada-002"
      },
      "name": "fluentcli_retriever",
      "description": "fluentcli source code retriever",
      "returnSourceDocuments": true
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "GPT4FunctionAgentWithMemoryAndBrowsingRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "154f3d8c-ec10-4828-b62b-153834f48dac",
    "request_path": "/api/v1/prediction/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "openAIApiKey": "AMBER_FLUENT_OPENAI_API_KEY_01",
      "searchApiKey": "AMBER_FLUENT_SEARCHAPI_KEY_ID_01",
      "allowImageUploads": true,
      "systemMessage": "You are a helpful assistant",
      "temperature": 0.9,
      "openAIToolAgent_0": {
        "systemMessage": "You are a helpful assistant"
      }
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },

  {
    "name": "PerplexitySonarLargeOnlineChainRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "d2dc60d5-beaf-43d5-a7fa-3e1498bb9c4f",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "modelName": "llama-3-sonar-large-32k-online",
      "openAIApiKey": "AMBER_FLUENT_PERPLEXITY_API_KEY_01",
      "allowImageUploads": false,
      "temperature": 0.9,
      "frequencyPenalty": 0.9,
      "systemMessage": "You are a helpful assistant",
      "openAIToolAgent_0": {

      }
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "PerplexitySonarSmallOnlineChainRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "d2dc60d5-beaf-43d5-a7fa-3e1498bb9c4f",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "modelName": "sonar-small-online",
      "openAIApiKey": "AMBER_FLUENT_PERPLEXITY_API_KEY_01",
      "allowImageUploads": false,
      "temperature": 0.9,
      "frequencyPenalty": 0.9,
      "openAIToolAgent_0": {
        "systemMessage": "You are a helpful assistant"
      }
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },

  {
    "name": "MistralLargeToolAgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "c541d269-56e2-4b3c-b1db-5767cf1d04c8",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "mistralAIAPIKey": "AMBER_FLUENT_MISTRAL_KEY_01",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "maxIterations": 10,
      "systemMessage": "You are a helpful assistant"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },

  {
    "name": "GroqMixtral8x7bAgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "e526c370-8c7c-4193-bd72-4fe660228a86",
    "request_path": "/api/v1/prediction/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "groqApiKey": "AMBER_FLUENT_GROQ_API_KEY_01",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "chainName": "groqChain",
      "systemMessagePrompt": "You are a helpful assistant",
      "temperature": 0.8,
      "modelName": "mixtral-8x7b-32768"
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "GroqLLama370b8192AgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "e526c370-8c7c-4193-bd72-4fe660228a86",
    "request_path": "/api/v1/prediction/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "groqApiKey": "AMBER_FLUENT_GROQ_API_KEY_01",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "chainName": "groqChain",
      "systemMessagePrompt": "You are a helpful assistant",
      "temperature": 0.8,
      "modelName":"llama3-70b-8192",
      "memoryKey": "AMBER_FLUENT_SESSION_ID_01"
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "GroqLLama38bToolAgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "flowise.fluentcli.com",
    "port": 443,
    "chat_id": "e526c370-8c7c-4193-bd72-4fe660228a86",
    "request_path": "/api/v1/prediction/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "groqApiKey": "AMBER_FLUENT_GROQ_API_KEY_01",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "chainName": "groqChain",
      "systemMessagePrompt": "You are a helpful assistant",
      "temperature": 0.8,
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "modelName":"llama3-8b-8192",
      "memoryKey": "AMBER_FLUENT_SESSION_ID_01"
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },
  {
    "name": "GroqGemma7bAgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "e526c370-8c7c-4193-bd72-4fe660228a86",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "groqApiKey": "AMBER_FLUENT_GROQ_API_KEY_01",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "chainName": "groqChain",
      "systemMessagePrompt": "You are a helpful assistant",
      "temperature": 0.5,
      "modelName":"gemma-7b-it",
      "memoryKey": "AMBER_FLUENT_SESSION_ID_01"
    },
    "tweaks": {

    },
    "timeout_ms": 500000
  },

  {
    "name": "SonnetXMLAgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "9634304b-6b2a-44cf-ad61-e1afadaf7bf1",
    "request_path": "/api/v1/prediction/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "stripNewLines": true,
      "modelName": {
        "chatAnthropic_1": "claude-3-sonnet-20240229",
        "chatOpenAI_1": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_1": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "SystemMessage": "You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nPrevious Conversation:\n{chat_history}\n\nQuestion: {input}\n{agent_scratchpad}",
      "temperature": 0.2

    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "SonnetToolAgentWithSearchAndWebRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "0d6dc743-f7f0-41ba-92c5-404a37e2ca13",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "modelName": {
        "chatAnthropic_0": "claude-3-sonnet-20240229",
        "chatOpenAI_0": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "SonnetChain",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "e1d50e5f-bacf-4b84-ac22-3ad4c9ca4d57",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "modelName": {
        "chatAnthropic_0": "claude-3-sonnet-20240229",
        "chatOpenAI_0": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "systemMessagePrompt": "you are a helpful assistant",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },

  {
    "name": "HaikuXMLAgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "9634304b-6b2a-44cf-ad61-e1afadaf7bf1",
    "request_path": "/api/v1/prediction/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "stripNewLines": true,
      "modelName": {
        "chatAnthropic_1": "claude-3-haiku-20240307",
        "chatOpenAI_1": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_1": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "SystemMessage": "You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nPrevious Conversation:\n{chat_history}\n\nQuestion: {input}\n{agent_scratchpad}",
      "temperature": 0.8

    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "HaikuChain",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "e1d50e5f-bacf-4b84-ac22-3ad4c9ca4d57",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "modelName": {
        "chatAnthropic_0": "claude-3-haiku-20240307",
        "chatOpenAI_0": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "systemMessagePrompt": "you are a helpful assistant",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },

  {
    "name": "OpusXMLAgentRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "9634304b-6b2a-44cf-ad61-e1afadaf7bf1",
    "request_path": "/api/v1/prediction/",
    "upsert_path": "/api/v1/upsert/",
    "sessionId": "",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "sessionId": "AMBER_FLUENT_SESSION_ID_01",
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "stripNewLines": true,
      "modelName": {
        "chatAnthropic_1": "claude-3-opus-20240229",
        "chatOpenAI_1": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_1": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "SystemMessage": "You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nPrevious Conversation:\n{chat_history}\n\nQuestion: {input}\n{agent_scratchpad}",
      "temperature": 0.8
    },
    "tweaks": {

  },
    "timeout_ms": 50000
  },
  {
    "name": "OpusToolAgentWithSearchAndWebRepoCloud",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "0d6dc743-f7f0-41ba-92c5-404a37e2ca13",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "stripNewLines": true,
      "modelName": {
        "chatAnthropic_0": "claude-3-opus-20240229",
        "chatOpenAI_0": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01",
      "SystemMessage": "You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nPrevious Conversation:\n{chat_history}\n\nQuestion: {input}\n{agent_scratchpad}",
      "temperature": 0.2

    },
    "tweaks": {

    },
    "timeout_ms": 50000
  },
  {
    "name": "OpusChain",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "9d81nz4o.rpcld.co",
    "port": 443,
    "chat_id": "e1d50e5f-bacf-4b84-ac22-3ad4c9ca4d57",
    "request_path": "/api/v1/prediction/",
    "sessionId": "AMBER_FLUENT_SESSION_ID_01",
    "bearer_token": "AMBER_REPO_CLOUD_FLUENT_DEMO_KEY",
    "overrideConfig": {
      "stripNewLines": true,
      "anthropicApiKey": "AMBER_FLUENT_ANTHROPIC_KEY_01",
      "modelName": {
        "chatAnthropic_0": "claude-3-opus-20240229",
        "chatOpenAI_0": "gpt-3.5-turbo-16k",
        "openAIEmbeddings_0": "text-embedding-3-small"
      },
      "openAIApiKey": {
        "openAIEmbeddings_0": "AMBER_FLUENT_OPENAI_API_KEY_01",
        "chatOpenAI_0": "AMBER_FLUENT_OPENAI_API_KEY_01"
      },
      "systemMessagePrompt": "you are a helpful assistant",
      "serpApiKey": "AMBER_FLUENT_SERPAPI_KEY_01"
    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },

  {
    "name": "MakeDalleImagePost",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "hook.us1.make.com",
    "port": 443,
    "chat_id": "wy6osfep6j1s4iamkyimx6yuabbnfgrq",
    "request_path": "/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "size": "1024x1792",
      "quality":"HD",
      "style": "Vivid",
      "responseFormat": "url",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST"

    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },  {
    "name": "MakeGoogleDocsCreator",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "hook.us1.make.com",
    "port": 443,
    "chat_id": "m498sj3xj46i8jr9l0bx2wg5f1lqcxqo",
    "request_path": "/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "title": "Google Docs",
      "tags": "Test"
    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },
  {
    "name": "MakeDalleImagePostRawOutput",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "hook.us1.make.com",
    "port": 443,
    "chat_id": "ns0sts8l8tqgeztgyftrdpvrsc1jas7m",
    "request_path": "/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "size": "1024x1792",
      "quality":"HD",
      "style": "Vivid",
      "responseFormat": "url",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST"

    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },
  {
    "name": "MakeLeonardoImagePost",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "hook.us1.make.com",
    "port": 443,
    "chat_id": "19riyltebstlvc3q1tvei7s7jduld8xa",
    "request_path": "/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "modelID": "AMBER_LEONARDO_AI_KINO_XL_MODEL_ID",
      "negative_prompt": "words, letters, symbols, hands, deformities, low-quality,",
      "alchemy": true,
      "photoReal": true,
      "photoRealVersion":"v2",
      "presetStyle": "",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST",
      "seed": ""
    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },
  {
    "name": "MakeLeonardoImagePostRawOutput",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "hook.us1.make.com",
    "port": 443,
    "chat_id": "hbxg9tuxhh9bjki2reop2993ogbjr6ej",
    "request_path": "/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "modelID": "AMBER_LEONARDO_AI_KINO_XL_MODEL_ID",
      "negative_prompt": "words, letters, symbols, hands, deformities, low-quality,",
      "alchemy": true,
      "photoReal": true,
      "photoRealVersion":"v2",
      "presetStyle": "",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST",
      "seed": ""
    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },
  {
    "name": "MakeLeonardoImagePostTest",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "hook.us1.make.com",
    "port": 443,
    "chat_id": "19riyltebstlvc3q1tvei7s7jduld8xa",
    "request_path": "/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "modelID": "AMBER_LEONARDO_AI_KINO_XL_MODEL_ID",
      "negative_prompt": "words, letters, symbols, hands, deformities, low-quality,",
      "alchemy": true,
      "photoReal": true,
      "photoRealVersion":"v2",
      "presetStyle": "CINEMATIC",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST",
      "seed": ""
    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },
  {
    "name": "MakeShopifyAndGhostPostExample",
    "engine": "flowise",
    "protocol": "https",
    "hostname": "hook.us1.make.com",
    "port": 443,
    "chat_id": "idagdtlvmn7hhedt91cqx38mla3p5kco",
    "request_path": "/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "modelID": "AMBER_LEONARDO_AI_KINO_XL_MODEL_ID",
      "negative_prompt": "words, letters, symbols, hands, deformities, low-quality,",
      "alchemy": true,
      "photoReal": true,
      "photoRealVersion":"v2",
      "presetStyle": "CINEMATIC",
      "makeAuthentication": "AMBER_MAKE_SHOPIFY_GHOST_POST_KEY",
      "seed": ""
    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },

  {
    "name": "N8NDalleImagePostTest",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "kvnnmo99-n8n.myjfmo.easypanel.host",
    "port": 443,
    "chat_id": "cdf12254-e7c0-49fb-91a9-00a3995d70cd",
    "request_path": "/webhook-test/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "size": "1024x1792",
      "quality":"HD",
      "style": "Vivid",
      "responseFormat": "url",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST"

    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },
  {
    "name": "N8NDalleImagePost",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "kvnnmo99-n8n.myjfmo.easypanel.host",
    "port": 443,
    "chat_id": "cdf12254-e7c0-49fb-91a9-00a3995d70cd",
    "request_path": "/webhook/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "size": "1024x1792",
      "quality":"HD",
      "style": "Vivid",
      "responseFormat": "url",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST"

    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },
  {
    "name": "N8NChatFlow",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "kvnnmo99-n8n.myjfmo.easypanel.host",
    "port": 443,
    "chat_id": "8f0d0b79-9359-427f-93c0-fa1b8824eba5",
    "request_path": "/webhook/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "size": "1024x1792",
      "quality":"HD",
      "style": "Vivid",
      "responseFormat": "url",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST"

    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  },
  {
    "name": "TESTN8NChatFlow",
    "engine": "webhook",
    "protocol": "https",
    "hostname": "kvnnmo99-n8n.myjfmo.easypanel.host",
    "port": 443,
    "chat_id": "8f0d0b79-9359-427f-93c0-fa1b8824eba5",
    "request_path": "/webhook-test/",
    "sessionId": "",
    "bearer_token": "AMBER_MAKE_LEONARDO_IMAGE_POST",
    "overrideConfig": {
      "size": "1024x1792",
      "quality":"HD",
      "style": "Vivid",
      "responseFormat": "url",
      "makeAuthentication": "AMBER_MAKE_LEONARDO_IMAGE_POST"

    },
    "tweaks": {

    },
    "timeout_ms": 5000000
  }

]
